{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T01:39:59.565632Z",
     "start_time": "2024-07-12T01:39:57.624072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset  \n",
    "import torch  \n",
    "from torch.utils.data import Sampler\n",
    "from torch.utils.data import DataLoader\n",
    "from qlib.data.dataset.processor import RobustZScoreNorm, Fillna, DropnaLabel, CSZScoreNorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from qlib.data.dataset import TSDataSampler"
   ],
   "id": "77b617cf19b0d06e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T01:40:02.591409Z",
     "start_time": "2024-07-12T01:40:02.574409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings  \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ],
   "id": "2ba7194f7e30101e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T01:43:43.511640Z",
     "start_time": "2024-07-12T01:43:43.389205Z"
    }
   },
   "cell_type": "code",
   "source": "cp = pd.read_parquet('D:\\CX_code\\Graph series\\MASTER\\data\\\\000300.XSHG_component.pq')",
   "id": "9898b46bc0061927",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T01:43:50.977705Z",
     "start_time": "2024-07-12T01:43:50.955706Z"
    }
   },
   "cell_type": "code",
   "source": "print(cp)",
   "id": "73cfcd66d00d179",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker      000001.XSHE  000002.XSHE  000008.XSHE  000009.XSHE  000027.XSHE  \\\n",
      "date                                                                          \n",
      "2016-01-04          1.0          1.0          NaN          1.0          1.0   \n",
      "2016-01-05          1.0          1.0          NaN          1.0          1.0   \n",
      "2016-01-06          1.0          1.0          NaN          1.0          1.0   \n",
      "2016-01-07          1.0          1.0          NaN          1.0          1.0   \n",
      "2016-01-08          1.0          1.0          NaN          1.0          1.0   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2024-06-26          1.0          1.0          NaN          NaN          NaN   \n",
      "2024-06-27          1.0          1.0          NaN          NaN          NaN   \n",
      "2024-06-28          1.0          1.0          NaN          NaN          NaN   \n",
      "2024-07-01          1.0          1.0          NaN          NaN          NaN   \n",
      "2024-07-02          1.0          1.0          NaN          NaN          NaN   \n",
      "\n",
      "ticker      000039.XSHE  000046.XSHE  000060.XSHE  000061.XSHE  000063.XSHE  \\\n",
      "date                                                                          \n",
      "2016-01-04          1.0          1.0          1.0          1.0          1.0   \n",
      "2016-01-05          1.0          1.0          1.0          1.0          1.0   \n",
      "2016-01-06          1.0          1.0          1.0          1.0          1.0   \n",
      "2016-01-07          1.0          1.0          1.0          1.0          1.0   \n",
      "2016-01-08          1.0          1.0          1.0          1.0          1.0   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2024-06-26          NaN          NaN          NaN          NaN          1.0   \n",
      "2024-06-27          NaN          NaN          NaN          NaN          1.0   \n",
      "2024-06-28          NaN          NaN          NaN          NaN          1.0   \n",
      "2024-07-01          NaN          NaN          NaN          NaN          1.0   \n",
      "2024-07-02          NaN          NaN          NaN          NaN          1.0   \n",
      "\n",
      "ticker      ...  688187.XSHG  688223.XSHG  688256.XSHG  688271.XSHG  \\\n",
      "date        ...                                                       \n",
      "2016-01-04  ...          NaN          NaN          NaN          NaN   \n",
      "2016-01-05  ...          NaN          NaN          NaN          NaN   \n",
      "2016-01-06  ...          NaN          NaN          NaN          NaN   \n",
      "2016-01-07  ...          NaN          NaN          NaN          NaN   \n",
      "2016-01-08  ...          NaN          NaN          NaN          NaN   \n",
      "...         ...          ...          ...          ...          ...   \n",
      "2024-06-26  ...          1.0          1.0          1.0          1.0   \n",
      "2024-06-27  ...          1.0          1.0          1.0          1.0   \n",
      "2024-06-28  ...          1.0          1.0          1.0          1.0   \n",
      "2024-07-01  ...          1.0          1.0          1.0          1.0   \n",
      "2024-07-02  ...          1.0          1.0          1.0          1.0   \n",
      "\n",
      "ticker      688303.XSHG  688363.XSHG  688396.XSHG  688561.XSHG  688599.XSHG  \\\n",
      "date                                                                          \n",
      "2016-01-04          NaN          NaN          NaN          NaN          NaN   \n",
      "2016-01-05          NaN          NaN          NaN          NaN          NaN   \n",
      "2016-01-06          NaN          NaN          NaN          NaN          NaN   \n",
      "2016-01-07          NaN          NaN          NaN          NaN          NaN   \n",
      "2016-01-08          NaN          NaN          NaN          NaN          NaN   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2024-06-26          1.0          1.0          1.0          NaN          1.0   \n",
      "2024-06-27          1.0          1.0          1.0          NaN          1.0   \n",
      "2024-06-28          1.0          1.0          1.0          NaN          1.0   \n",
      "2024-07-01          1.0          1.0          1.0          NaN          1.0   \n",
      "2024-07-02          1.0          1.0          1.0          NaN          1.0   \n",
      "\n",
      "ticker      688981.XSHG  \n",
      "date                     \n",
      "2016-01-04          NaN  \n",
      "2016-01-05          NaN  \n",
      "2016-01-06          NaN  \n",
      "2016-01-07          NaN  \n",
      "2016-01-08          NaN  \n",
      "...                 ...  \n",
      "2024-06-26          1.0  \n",
      "2024-06-27          1.0  \n",
      "2024-06-28          1.0  \n",
      "2024-07-01          1.0  \n",
      "2024-07-02          1.0  \n",
      "\n",
      "[2064 rows x 608 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:22.639337Z",
     "start_time": "2024-07-10T07:47:58.099728Z"
    }
   },
   "source": [
    "# step1:获取数据并生成复制\n",
    "df_test = pd.read_parquet('combined_data.pq')\n",
    "\n",
    "# step2:设置双重列索引\n",
    "level0 = ['feature'] * 44 + ['label']  # 第一层索引：前44列为'feature'，最后一列为'label'\n",
    "level1 = list(df_test.keys())\n",
    "multi_index = pd.MultiIndex.from_tuples(list(zip(level0, level1)))\n",
    "df_test.columns = multi_index\n",
    "# print(df_test.head())\n",
    "\n",
    "# step3:设置双重行索引\n",
    "# print(\"Original index names:\", df_test.index.names)\n",
    "df_test.index.names = ['datetime', 'instrument']\n",
    "# print(\"New index names:\", df_test.index.names)\n",
    "# print(df_test.index)\n",
    "df_sorted = df_test.sort_index()\n",
    "# print(df_sorted.index)\n",
    "df_sorted = df_sorted[df_sorted['label'][\"label\"] != 0]\n",
    "\n",
    "# step4:数据预处理\n",
    "# print(df_test.index.get_level_values(0).unique())\n",
    "# row_counts = df_test.groupby(level=0).size()\n",
    "# print(row_counts)\n",
    "RobustZScoreNorm = RobustZScoreNorm(fit_start_time='20160101', fit_end_time='20170501', fields_group='feature', clip_outlier=True)\n",
    "Fillna = Fillna(fields_group='feature')\n",
    "CSZScoreNorm = CSZScoreNorm(fields_group='label')\n",
    "\n",
    "RobustZScoreNorm.fit(df_sorted)\n",
    "for process_func in [RobustZScoreNorm, Fillna, CSZScoreNorm]:\n",
    "    df_process = process_func(df_sorted)\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "4664d5ed56aa3696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:22.671327Z",
     "start_time": "2024-07-10T07:49:22.640327Z"
    }
   },
   "source": [
    "feature_mean = df_process['label'].mean()\n",
    "feature_std = df_process['label'].std()\n",
    "\n",
    "print(f\"Mean of 'feature_column' after preprocessing: {feature_mean}\")\n",
    "print(f\"Standard deviation of 'feature_column' after preprocessing: {feature_std}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'feature_column' after preprocessing: label    2.121197e-19\n",
      "dtype: float64\n",
      "Standard deviation of 'feature_column' after preprocessing: label    0.999819\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "9a157d03a6cebe7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:22.687326Z",
     "start_time": "2024-07-10T07:49:22.674328Z"
    }
   },
   "source": [
    "print(df_test.shape)\n",
    "print(df_process.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1495317, 45)\n",
      "(1339890, 45)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "e3faca6c7f100b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:22.719277Z",
     "start_time": "2024-07-10T07:49:22.689327Z"
    }
   },
   "source": [
    "df_test['label']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           label\n",
       "datetime   instrument           \n",
       "2016-01-29 000001.XSHE  0.001013\n",
       "           000004.XSHE -0.030452\n",
       "           000005.XSHE -0.020498\n",
       "           000006.XSHE -0.061911\n",
       "           000008.XSHE  0.025485\n",
       "...                          ...\n",
       "2017-12-29 002920.XSHE  0.100000\n",
       "           600145.XSHG  0.000000\n",
       "           601313.XSHG  0.000000\n",
       "           601360.XSHG  0.000000\n",
       "           603283.XSHG  0.099726\n",
       "\n",
       "[1495317 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th>instrument</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016-01-29</th>\n",
       "      <th>000001.XSHE</th>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004.XSHE</th>\n",
       "      <td>-0.030452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000005.XSHE</th>\n",
       "      <td>-0.020498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000006.XSHE</th>\n",
       "      <td>-0.061911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000008.XSHE</th>\n",
       "      <td>0.025485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017-12-29</th>\n",
       "      <th>002920.XSHE</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600145.XSHG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601313.XSHG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601360.XSHG</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603283.XSHG</th>\n",
       "      <td>0.099726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1495317 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "8a4b0ff5315da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:22.735276Z",
     "start_time": "2024-07-10T07:49:22.720276Z"
    }
   },
   "source": [
    "print(df_process.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1339890, 45)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "d6399309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:22.985695Z",
     "start_time": "2024-07-10T07:49:22.736277Z"
    }
   },
   "source": [
    "# 定义时间范围  \n",
    "train_range = pd.date_range('20160101', '20170331')  \n",
    "val_range = pd.date_range('20170401', '20170630')  \n",
    "test_range = pd.date_range('20170701', '20171231')  \n",
    "\n",
    "# 使用IndexSlice选择子集  \n",
    "idx = pd.IndexSlice  \n",
    "train_set = df_process.loc[idx[train_range, :], :]  \n",
    "val_set = df_process.loc[idx[val_range, :], :]  \n",
    "test_set = df_process.loc[idx[test_range, :], :]  \n",
    "\n",
    "# 展示各子集的信息  \n",
    "print(\"Training set shape:\", train_set.shape)  \n",
    "print(\"Validation set shape:\", val_set.shape)  \n",
    "print(\"Test set shape:\", test_set.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (784696, 45)\n",
      "Validation set shape: (173490, 45)\n",
      "Test set shape: (381704, 45)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "a23b72ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:23.016694Z",
     "start_time": "2024-07-10T07:49:22.988695Z"
    }
   },
   "source": [
    "class TSdataset(Dataset):  \n",
    "    def __init__(self, dataframe, seq_len=8):  \n",
    "        self.dataframe = dataframe  \n",
    "        self.seq_len = seq_len  \n",
    "        self.data = self.dataframe\n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.data) - self.seq_len\n",
    "  \n",
    "    def __getitem__(self, index):  \n",
    "        # 返回从idx开始，长度为window_size的序列作为输入，以及下一个值作为目标  \n",
    "        return (  \n",
    "            torch.tensor(self.data[idx:index + self.seq_len], dtype=torch.float32),  \n",
    "            torch.tensor(self.data[index + self.seq_len], dtype=torch.float32)  \n",
    "        )  \n",
    "  \n",
    "\n",
    "train_dataset = TSdataset(train_set)  \n",
    "val_dataset = TSdataset(val_set)  \n",
    "test_dataset = TSdataset(test_set) "
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:58:04.871032Z",
     "start_time": "2024-07-10T07:58:04.854065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DailyBatchSamplerRandom(Sampler):\n",
    "    def __init__(self, data_source, shuffle=False):\n",
    "        self.data_source = data_source\n",
    "        self.shuffle = shuffle\n",
    "        # calculate number of samples in each batch\n",
    "        self.daily_count = pd.Series(index=self.data_source.get_index()).groupby(\"datetime\").size().values\n",
    "        self.daily_index = np.roll(np.cumsum(self.daily_count), 1)  # calculate begin index of each batch\n",
    "        self.daily_index[0] = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            index = np.arange(len(self.daily_count))\n",
    "            np.random.shuffle(index)\n",
    "            for i in index:\n",
    "                yield np.arange(self.daily_index[i], self.daily_index[i] + self.daily_count[i])\n",
    "        else:\n",
    "            for idx, count in zip(self.daily_index, self.daily_count):\n",
    "                yield np.arange(idx, idx + count)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ],
   "id": "120cce0b0f8ce78d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:23.047694Z",
     "start_time": "2024-07-10T07:49:23.034694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _init_data_loader(data, shuffle=True, drop_last=True):\n",
    "    sampler = DailyBatchSamplerRandom(data, shuffle)\n",
    "    data_loader = DataLoader(data, sampler=sampler, drop_last=drop_last)\n",
    "    return data_loader"
   ],
   "id": "f2a14c9055b8cb43",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:23.095694Z",
     "start_time": "2024-07-10T07:49:23.049694Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader = _init_data_loader(train_set)",
   "id": "ebe9050a098e0552",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:49:23.173934Z",
     "start_time": "2024-07-10T07:49:23.098694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for data in train_loader:\n",
    "    data = torch.squeeze(data, dim=0)\n",
    "    feature = data[:, :, 0:-1]\n",
    "    label = data[:, -1, -1]"
   ],
   "id": "38231a9613b83ac1",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[395906 395907 395908 ... 398509 398510 398511] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      2\u001B[0m     data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msqueeze(data, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      3\u001B[0m     feature \u001B[38;5;241m=\u001B[39m data[:, :, \u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\Master\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\.conda\\envs\\Master\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Master\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\.conda\\envs\\Master\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\.conda\\envs\\Master\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3811\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   3812\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 3813\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   3815\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\Master\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:2623\u001B[0m, in \u001B[0;36mMultiIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   2620\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(keyarr) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(keyarr[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m   2621\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_indexer_level_0(keyarr)\n\u001B[1;32m-> 2623\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[indexer], indexer\n\u001B[0;32m   2626\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_get_indexer_strict(key, axis_name)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Master\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:2641\u001B[0m, in \u001B[0;36mMultiIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   2639\u001B[0m cmask \u001B[38;5;241m=\u001B[39m check \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2640\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cmask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m-> 2641\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkeyarr[cmask]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2642\u001B[0m \u001B[38;5;66;03m# We get here when levels still contain values which are not\u001B[39;00m\n\u001B[0;32m   2643\u001B[0m \u001B[38;5;66;03m# actually in Index anymore\u001B[39;00m\n\u001B[0;32m   2644\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkeyarr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: '[395906 395907 395908 ... 398509 398510 398511] not in index'"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T08:22:27.997514Z",
     "start_time": "2024-07-10T08:22:14.883230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampler = TSDataSampler(train_set, '20160101', '20170331', step_len=8, fillna_type=\"ffill+bfill\")\n",
    "train_loader = _init_data_loader(sampler)\n",
    "for data in train_loader:\n",
    "    data = torch.squeeze(data, dim=0)\n",
    "    print(data.shape)"
   ],
   "id": "c2bdbd79cb2489da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2576, 8, 45])\n",
      "torch.Size([2720, 8, 45])\n",
      "torch.Size([2756, 8, 45])\n",
      "torch.Size([2502, 8, 45])\n",
      "torch.Size([2630, 8, 45])\n",
      "torch.Size([2520, 8, 45])\n",
      "torch.Size([2553, 8, 45])\n",
      "torch.Size([2573, 8, 45])\n",
      "torch.Size([2517, 8, 45])\n",
      "torch.Size([2524, 8, 45])\n",
      "torch.Size([2544, 8, 45])\n",
      "torch.Size([2590, 8, 45])\n",
      "torch.Size([2651, 8, 45])\n",
      "torch.Size([2550, 8, 45])\n",
      "torch.Size([2637, 8, 45])\n",
      "torch.Size([2578, 8, 45])\n",
      "torch.Size([2665, 8, 45])\n",
      "torch.Size([2509, 8, 45])\n",
      "torch.Size([2516, 8, 45])\n",
      "torch.Size([2636, 8, 45])\n",
      "torch.Size([2491, 8, 45])\n",
      "torch.Size([2435, 8, 45])\n",
      "torch.Size([2514, 8, 45])\n",
      "torch.Size([2638, 8, 45])\n",
      "torch.Size([2494, 8, 45])\n",
      "torch.Size([2644, 8, 45])\n",
      "torch.Size([2556, 8, 45])\n",
      "torch.Size([2583, 8, 45])\n",
      "torch.Size([2583, 8, 45])\n",
      "torch.Size([2855, 8, 45])\n",
      "torch.Size([2671, 8, 45])\n",
      "torch.Size([2484, 8, 45])\n",
      "torch.Size([2812, 8, 45])\n",
      "torch.Size([2509, 8, 45])\n",
      "torch.Size([2601, 8, 45])\n",
      "torch.Size([2563, 8, 45])\n",
      "torch.Size([2483, 8, 45])\n",
      "torch.Size([2557, 8, 45])\n",
      "torch.Size([2538, 8, 45])\n",
      "torch.Size([2610, 8, 45])\n",
      "torch.Size([2550, 8, 45])\n",
      "torch.Size([2553, 8, 45])\n",
      "torch.Size([2771, 8, 45])\n",
      "torch.Size([2862, 8, 45])\n",
      "torch.Size([2537, 8, 45])\n",
      "torch.Size([2672, 8, 45])\n",
      "torch.Size([2816, 8, 45])\n",
      "torch.Size([2550, 8, 45])\n",
      "torch.Size([2541, 8, 45])\n",
      "torch.Size([2490, 8, 45])\n",
      "torch.Size([2822, 8, 45])\n",
      "torch.Size([2755, 8, 45])\n",
      "torch.Size([2606, 8, 45])\n",
      "torch.Size([2582, 8, 45])\n",
      "torch.Size([2477, 8, 45])\n",
      "torch.Size([2710, 8, 45])\n",
      "torch.Size([2546, 8, 45])\n",
      "torch.Size([2478, 8, 45])\n",
      "torch.Size([2528, 8, 45])\n",
      "torch.Size([2659, 8, 45])\n",
      "torch.Size([2497, 8, 45])\n",
      "torch.Size([2813, 8, 45])\n",
      "torch.Size([2720, 8, 45])\n",
      "torch.Size([2543, 8, 45])\n",
      "torch.Size([2521, 8, 45])\n",
      "torch.Size([2565, 8, 45])\n",
      "torch.Size([2542, 8, 45])\n",
      "torch.Size([2894, 8, 45])\n",
      "torch.Size([2541, 8, 45])\n",
      "torch.Size([2691, 8, 45])\n",
      "torch.Size([2562, 8, 45])\n",
      "torch.Size([2697, 8, 45])\n",
      "torch.Size([2422, 8, 45])\n",
      "torch.Size([2588, 8, 45])\n",
      "torch.Size([2796, 8, 45])\n",
      "torch.Size([2574, 8, 45])\n",
      "torch.Size([2448, 8, 45])\n",
      "torch.Size([2580, 8, 45])\n",
      "torch.Size([2841, 8, 45])\n",
      "torch.Size([2661, 8, 45])\n",
      "torch.Size([2577, 8, 45])\n",
      "torch.Size([2830, 8, 45])\n",
      "torch.Size([2505, 8, 45])\n",
      "torch.Size([2696, 8, 45])\n",
      "torch.Size([2510, 8, 45])\n",
      "torch.Size([2476, 8, 45])\n",
      "torch.Size([2524, 8, 45])\n",
      "torch.Size([2770, 8, 45])\n",
      "torch.Size([2539, 8, 45])\n",
      "torch.Size([2656, 8, 45])\n",
      "torch.Size([2472, 8, 45])\n",
      "torch.Size([2758, 8, 45])\n",
      "torch.Size([2474, 8, 45])\n",
      "torch.Size([2556, 8, 45])\n",
      "torch.Size([2478, 8, 45])\n",
      "torch.Size([2794, 8, 45])\n",
      "torch.Size([2626, 8, 45])\n",
      "torch.Size([2523, 8, 45])\n",
      "torch.Size([2516, 8, 45])\n",
      "torch.Size([2787, 8, 45])\n",
      "torch.Size([2667, 8, 45])\n",
      "torch.Size([2564, 8, 45])\n",
      "torch.Size([2730, 8, 45])\n",
      "torch.Size([2469, 8, 45])\n",
      "torch.Size([2511, 8, 45])\n",
      "torch.Size([2470, 8, 45])\n",
      "torch.Size([2537, 8, 45])\n",
      "torch.Size([2674, 8, 45])\n",
      "torch.Size([2545, 8, 45])\n",
      "torch.Size([2469, 8, 45])\n",
      "torch.Size([2452, 8, 45])\n",
      "torch.Size([2468, 8, 45])\n",
      "torch.Size([2708, 8, 45])\n",
      "torch.Size([2711, 8, 45])\n",
      "torch.Size([2428, 8, 45])\n",
      "torch.Size([2810, 8, 45])\n",
      "torch.Size([2555, 8, 45])\n",
      "torch.Size([2611, 8, 45])\n",
      "torch.Size([2690, 8, 45])\n",
      "torch.Size([2478, 8, 45])\n",
      "torch.Size([2711, 8, 45])\n",
      "torch.Size([2469, 8, 45])\n",
      "torch.Size([2650, 8, 45])\n",
      "torch.Size([2410, 8, 45])\n",
      "torch.Size([2493, 8, 45])\n",
      "torch.Size([2676, 8, 45])\n",
      "torch.Size([2496, 8, 45])\n",
      "torch.Size([2833, 8, 45])\n",
      "torch.Size([2549, 8, 45])\n",
      "torch.Size([2738, 8, 45])\n",
      "torch.Size([2544, 8, 45])\n",
      "torch.Size([2812, 8, 45])\n",
      "torch.Size([2488, 8, 45])\n",
      "torch.Size([2519, 8, 45])\n",
      "torch.Size([2562, 8, 45])\n",
      "torch.Size([2538, 8, 45])\n",
      "torch.Size([2689, 8, 45])\n",
      "torch.Size([2538, 8, 45])\n",
      "torch.Size([2579, 8, 45])\n",
      "torch.Size([2443, 8, 45])\n",
      "torch.Size([2883, 8, 45])\n",
      "torch.Size([2473, 8, 45])\n",
      "torch.Size([2533, 8, 45])\n",
      "torch.Size([2720, 8, 45])\n",
      "torch.Size([2736, 8, 45])\n",
      "torch.Size([2514, 8, 45])\n",
      "torch.Size([2795, 8, 45])\n",
      "torch.Size([2801, 8, 45])\n",
      "torch.Size([2779, 8, 45])\n",
      "torch.Size([2784, 8, 45])\n",
      "torch.Size([2567, 8, 45])\n",
      "torch.Size([2510, 8, 45])\n",
      "torch.Size([2854, 8, 45])\n",
      "torch.Size([2787, 8, 45])\n",
      "torch.Size([2458, 8, 45])\n",
      "torch.Size([2754, 8, 45])\n",
      "torch.Size([2664, 8, 45])\n",
      "torch.Size([2847, 8, 45])\n",
      "torch.Size([2493, 8, 45])\n",
      "torch.Size([2449, 8, 45])\n",
      "torch.Size([2837, 8, 45])\n",
      "torch.Size([2585, 8, 45])\n",
      "torch.Size([2691, 8, 45])\n",
      "torch.Size([2527, 8, 45])\n",
      "torch.Size([2674, 8, 45])\n",
      "torch.Size([2483, 8, 45])\n",
      "torch.Size([2697, 8, 45])\n",
      "torch.Size([2852, 8, 45])\n",
      "torch.Size([2517, 8, 45])\n",
      "torch.Size([2749, 8, 45])\n",
      "torch.Size([2654, 8, 45])\n",
      "torch.Size([2770, 8, 45])\n",
      "torch.Size([2780, 8, 45])\n",
      "torch.Size([2688, 8, 45])\n",
      "torch.Size([2625, 8, 45])\n",
      "torch.Size([2772, 8, 45])\n",
      "torch.Size([2595, 8, 45])\n",
      "torch.Size([2536, 8, 45])\n",
      "torch.Size([2487, 8, 45])\n",
      "torch.Size([2775, 8, 45])\n",
      "torch.Size([2491, 8, 45])\n",
      "torch.Size([2717, 8, 45])\n",
      "torch.Size([2522, 8, 45])\n",
      "torch.Size([2571, 8, 45])\n",
      "torch.Size([2621, 8, 45])\n",
      "torch.Size([2491, 8, 45])\n",
      "torch.Size([2847, 8, 45])\n",
      "torch.Size([2556, 8, 45])\n",
      "torch.Size([2533, 8, 45])\n",
      "torch.Size([2779, 8, 45])\n",
      "torch.Size([2568, 8, 45])\n",
      "torch.Size([2517, 8, 45])\n",
      "torch.Size([2531, 8, 45])\n",
      "torch.Size([2792, 8, 45])\n",
      "torch.Size([2518, 8, 45])\n",
      "torch.Size([2680, 8, 45])\n",
      "torch.Size([2529, 8, 45])\n",
      "torch.Size([2526, 8, 45])\n",
      "torch.Size([2423, 8, 45])\n",
      "torch.Size([2577, 8, 45])\n",
      "torch.Size([2549, 8, 45])\n",
      "torch.Size([2789, 8, 45])\n",
      "torch.Size([2788, 8, 45])\n",
      "torch.Size([2732, 8, 45])\n",
      "torch.Size([2840, 8, 45])\n",
      "torch.Size([2458, 8, 45])\n",
      "torch.Size([2875, 8, 45])\n",
      "torch.Size([2775, 8, 45])\n",
      "torch.Size([2854, 8, 45])\n",
      "torch.Size([2815, 8, 45])\n",
      "torch.Size([2433, 8, 45])\n",
      "torch.Size([2774, 8, 45])\n",
      "torch.Size([2542, 8, 45])\n",
      "torch.Size([2474, 8, 45])\n",
      "torch.Size([2645, 8, 45])\n",
      "torch.Size([2733, 8, 45])\n",
      "torch.Size([2648, 8, 45])\n",
      "torch.Size([2478, 8, 45])\n",
      "torch.Size([2506, 8, 45])\n",
      "torch.Size([2707, 8, 45])\n",
      "torch.Size([2860, 8, 45])\n",
      "torch.Size([2700, 8, 45])\n",
      "torch.Size([2712, 8, 45])\n",
      "torch.Size([2671, 8, 45])\n",
      "torch.Size([2702, 8, 45])\n",
      "torch.Size([2560, 8, 45])\n",
      "torch.Size([2527, 8, 45])\n",
      "torch.Size([2538, 8, 45])\n",
      "torch.Size([2704, 8, 45])\n",
      "torch.Size([2733, 8, 45])\n",
      "torch.Size([2676, 8, 45])\n",
      "torch.Size([2723, 8, 45])\n",
      "torch.Size([2562, 8, 45])\n",
      "torch.Size([2556, 8, 45])\n",
      "torch.Size([2535, 8, 45])\n",
      "torch.Size([2825, 8, 45])\n",
      "torch.Size([2518, 8, 45])\n",
      "torch.Size([2671, 8, 45])\n",
      "torch.Size([2517, 8, 45])\n",
      "torch.Size([2632, 8, 45])\n",
      "torch.Size([2468, 8, 45])\n",
      "torch.Size([2837, 8, 45])\n",
      "torch.Size([2491, 8, 45])\n",
      "torch.Size([2690, 8, 45])\n",
      "torch.Size([2466, 8, 45])\n",
      "torch.Size([2527, 8, 45])\n",
      "torch.Size([2593, 8, 45])\n",
      "torch.Size([2514, 8, 45])\n",
      "torch.Size([2558, 8, 45])\n",
      "torch.Size([2690, 8, 45])\n",
      "torch.Size([2476, 8, 45])\n",
      "torch.Size([2536, 8, 45])\n",
      "torch.Size([2618, 8, 45])\n",
      "torch.Size([2671, 8, 45])\n",
      "torch.Size([2487, 8, 45])\n",
      "torch.Size([2563, 8, 45])\n",
      "torch.Size([2662, 8, 45])\n",
      "torch.Size([2493, 8, 45])\n",
      "torch.Size([2648, 8, 45])\n",
      "torch.Size([2842, 8, 45])\n",
      "torch.Size([2478, 8, 45])\n",
      "torch.Size([2585, 8, 45])\n",
      "torch.Size([2805, 8, 45])\n",
      "torch.Size([2532, 8, 45])\n",
      "torch.Size([2593, 8, 45])\n",
      "torch.Size([2523, 8, 45])\n",
      "torch.Size([2520, 8, 45])\n",
      "torch.Size([2542, 8, 45])\n",
      "torch.Size([2524, 8, 45])\n",
      "torch.Size([2779, 8, 45])\n",
      "torch.Size([2804, 8, 45])\n",
      "torch.Size([2777, 8, 45])\n",
      "torch.Size([2553, 8, 45])\n",
      "torch.Size([2571, 8, 45])\n",
      "torch.Size([2506, 8, 45])\n",
      "torch.Size([2505, 8, 45])\n",
      "torch.Size([2666, 8, 45])\n",
      "torch.Size([2536, 8, 45])\n",
      "torch.Size([2511, 8, 45])\n",
      "torch.Size([2625, 8, 45])\n",
      "torch.Size([2728, 8, 45])\n",
      "torch.Size([2486, 8, 45])\n",
      "torch.Size([2587, 8, 45])\n",
      "torch.Size([2785, 8, 45])\n",
      "torch.Size([2571, 8, 45])\n",
      "torch.Size([2688, 8, 45])\n",
      "torch.Size([2420, 8, 45])\n",
      "torch.Size([2638, 8, 45])\n",
      "torch.Size([2545, 8, 45])\n",
      "torch.Size([2678, 8, 45])\n",
      "torch.Size([2733, 8, 45])\n",
      "torch.Size([2664, 8, 45])\n",
      "torch.Size([2491, 8, 45])\n",
      "torch.Size([2844, 8, 45])\n",
      "torch.Size([2601, 8, 45])\n",
      "torch.Size([2605, 8, 45])\n",
      "torch.Size([2526, 8, 45])\n",
      "torch.Size([2533, 8, 45])\n",
      "torch.Size([2782, 8, 45])\n",
      "torch.Size([2485, 8, 45])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T07:58:11.158343Z",
     "start_time": "2024-07-10T07:58:11.120344Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aee41d04caaef6bd",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd9c8531932594cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
